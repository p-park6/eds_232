
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
---
title: "Lab5_Demo2"
author: "Mateo Robbins"
date: "2023-02-15"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidymodels)
library(vip) #variable importance
```
## R
```{r}
set.seed(123)
kaggle_dat <- read_csv(here::here("week_6", "data", "genres_v2.csv"))
unique(kaggle_dat$genre)
table(kaggle_dat$genre)

#Removing inappropriate columns and selecting trap and Hiphop as the two genres here and making case consistent
#removing type and string nonsense

genre_dat <- kaggle_dat %>%
  select(-c(type, uri, track_href, analysis_url, `Unnamed: 0`, title, tempo, id, song_name)) %>% #remove similar columns, just has info for the song itself
  filter(genre == "Hiphop"|genre == "Rap") %>%
  mutate(genre = str_replace(genre, "Hiphop", "hiphop")) %>%
  mutate(genre = str_replace(genre, "Rap", "rap")) %>%
  mutate(genre = as.factor(genre))
```

```{r}
##split the data
genre_split <- initial_split(genre_dat)
genre_train <- training(genre_split)
genre_test <- testing(genre_split)
```

```{r recipe}
#Preprocess the data
genre_rec <- recipe(genre ~. , data = genre_train) %>% 
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% 
  step_normalize(all_numeric_predictors()) #changes the interpretation
  
```

Set up a decision tree specification. Note: the cost_complexity parameter is a pruning penalty parameter that controls how much we penalize the number of terminal nodes in the tree.  It's conceptually similar to lambda from regularized regression.

```{r tree_specification}
#we already put in the values we want, this is why we dont have to tune
tree_spec_fixed <- decision_tree(
  cost_complexity = 0.1, #unique to decision trees and CART, its a penalizing thing
  tree_depth = 4, #how many nodes we want
  min_n = 11 #tree needs to consider x amount of the variables to see what it can minimize it by
) %>% 
  set_engine("rpart", times = ___) %>% ## YOU CAN ADD TIMES HERE
  set_mode("classification")
```

But, as usual, we don't want just any old values for our hyperparameters, we want optimal values.
```{r}
#new spec, tell the model that we are tuning hyperparams
#we are tuning to find the 'best' type of numbers
# we still need to fit them
tree_spec_tune <- decision_tree(
  cost_complexity = tune(), 
  tree_depth = tune(), 
  min_n = tune() 
) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

#gives us 5 different types of depths because we set it to 5
tree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 5)
```

```{r workflow_tree}
#setting it up in the workflow so it can be tuned in the next step
wf_tree_tune <- workflow() %>% 
  add_recipe(genre_rec) %>% 
  add_model(tree_spec_tune)

#tree_spec_tune and tree_spec_fixed are two slightly different classes
```

```{r resampling}
#set up k-fold cv. This can be used for all the algorithms
genre_cv <- genre_train %>% vfold_cv(v = 10)
genre_cv

```

```{r}
doParallel::registerDoParallel() #build trees in parallel
#200s
system.time(
  tree_rs <- tune_grid(
    wf_tree_tune, #or tree_spec_tune
    genre ~.,
    resamples = genre_cv,
    grid = tree_grid,
    metrics = metric_set(accuracy)
  )
)
tree_rs
```
Use autoplot() to examine how different parameter configurations relate to accuracy 
```{r}
autoplot(tree_rs) + theme_bw()

```

```{r select_hyperparam}
show_best(tree_rs)
```

We can finalize the model specification where we have replaced the tune functions with optimized values.

```{r final_tree_spec}
final_tree <- finalize_workflow(wf_tree_tune, select_best(tree_rs))

final_tree
```

This model has not been fit yet though.

```{r final_tree_fit}
#similar functions here.
final_tree_fit <- fit(final_tree, data = genre_train)
#last_fit() another function: fits on the training data but then evaluates on the test data
final_tree_result <- last_fit(final_tree, genre_split)
final_tree_result$.predictions
final_tree_result$.metrics
```

#Visualize variable importance
```{r tree_vip}
final_tree_fit %>% 
  vip(geom = "col", aesthetics = list(fill = "blue", alpha = 0.8)) +
  scale_y_continuous(expand = c(0,0))

```


